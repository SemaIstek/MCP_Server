{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab39c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loading CSV file: assets/filtered_data.csv\n",
      "üìä Rows: 2302, Columns: 9\n",
      "üìö Created 2302 documents\n",
      "‚úÖ Vector store created successfully\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1Ô∏è‚É£ Import libraries\n",
    "# -----------------------------\n",
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# -----------------------------\n",
    "# 2Ô∏è‚É£ Load CSV\n",
    "# -----------------------------\n",
    "csv_path = \"./assets/filtered_data.csv\"\n",
    "\n",
    "print(f\"üìÅ Loading CSV file: {csv_path}\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"üìä Rows: {len(df)}, Columns: {len(df.columns)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3Ô∏è‚É£ Create Documents (handle NaN)\n",
    "# -----------------------------\n",
    "documents = []\n",
    "for idx, row in df.iterrows():\n",
    "    # Replace NaN with \"N/A\"\n",
    "    values = [str(v) if pd.notna(v) else \"N/A\" for v in row.values]\n",
    "    content = \" | \".join(values)\n",
    "    documents.append(\n",
    "        Document(\n",
    "            page_content=content,\n",
    "            metadata={\"row_id\": idx}\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f\"üìö Created {len(documents)} documents\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4Ô∏è‚É£ Embedding model\n",
    "# -----------------------------\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5Ô∏è‚É£ Create FAISS vector store\n",
    "# -----------------------------\n",
    "vectorstore = FAISS.from_texts(\n",
    "    texts=[doc.page_content for doc in documents],\n",
    "    embedding=embeddings,\n",
    "    metadatas=[doc.metadata for doc in documents]\n",
    ")\n",
    "print(\"‚úÖ Vector store created successfully\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6Ô∏è‚É£ Create Retriever\n",
    "# -----------------------------\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# -----------------------------\n",
    "# 7Ô∏è‚É£ Setup LLM\n",
    "# -----------------------------\n",
    "llm = Ollama(model=\"llama3.2:1b\")\n",
    "\n",
    "# -----------------------------\n",
    "# 8Ô∏è‚É£ Define Prompt Template\n",
    "# -----------------------------\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are an assistant that answers questions using ONLY the CSV data.\n",
    "\n",
    "CSV DATA:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "If the answer is not in the CSV, say:\n",
    "\"I cannot find this information in the CSV.\"\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 9Ô∏è‚É£ Define RAG function\n",
    "# -----------------------------\n",
    "def ask(question: str):\n",
    "    # Use get_relevant_texts to avoid AttributeError\n",
    "    docs = retriever(question)  # bu bir liste d√∂nd√ºr√ºyor\n",
    "    context = \"\\n\".join(d.page_content for d in docs)\n",
    "    return llm.invoke(prompt.format(context=context, question=question))\n",
    "\n",
    "# ------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c8aa7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the vectorstore directly\n",
    "def ask(question: str):\n",
    "    # FAISS object has a method: similarity_search\n",
    "    docs = vectorstore.similarity_search(question, k=5)  # top 5 most similar docs\n",
    "    context = \"\\n\".join(d.page_content for d in docs)\n",
    "    return llm.invoke(prompt.format(context=context, question=question))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5338a19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "The data type of each column can be determined by examining their names and values.\n",
      "\n",
      "*   Natural: A variable that can hold any numeric value.\n",
      "*   Storm: A categorical variable with no numeric or textual representation.\n",
      "*   Sint Maarten (Dutch part): A categorical variable with two possible values.\n",
      "*   SXM: A variable containing a single value, but it's not clear if this is an index, category, or something else. However, I'll consider it as a categorical variable for the purpose of this analysis.\n",
      "*   4 and 32 are numerical values that can hold any type of numeric data.\n",
      "*   Flood: Another categorical variable with no numeric representation.\n",
      "\n",
      "So, this dataset appears to contain information about natural phenomena (storms, floods), volcanic activity, island locations, and population statistics.\n"
     ]
    }
   ],
   "source": [
    "# Test RAG system\n",
    "answer = ask(\"What information is stored in this dataset?\")\n",
    "print(f\"Answer:\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74164f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "To determine which country suffered the most damage, I will calculate the total \"Damage\" for each country based on the given data.\n",
      "\n",
      "First, I'll sum up all the values for \"Natural\" in the columns with unique countries:\n",
      "\n",
      "- India: 226806 + 197798 = 424604\n",
      "- Brazil: 197798 + 17897 = 216985\n",
      "- China: 99168 + 1018663 = 1029921\n",
      " \n",
      "\n",
      "Now, I'll sum up all the values for \"Mass movement (wet)\" in the columns with unique countries:\n",
      "\n",
      "- India: 8569.902547 + 3529081.3 = 3604170.802847\n",
      "- Brazil: 2824.715413 + 317756.5 = 306080.215913\n",
      "- China: 1053.112314 + 8474922.7 = 8485766.923\n",
      "\n",
      "Next, I'll compare the total \"Damage\" for each country to find out which one suffered the most damage:\n",
      "\n",
      "India had the highest total damage at 424604 units.\n",
      "Brazil and China also had a significant amount of damage but are tied as they have higher totals than India, with Brazil having 3604170.80 more units in damages than India.\n",
      "\n",
      "Therefore, I cannot find this information in the CSV.\n"
     ]
    }
   ],
   "source": [
    "answer = ask(\"Which country suffered the most damage?\")\n",
    "print(f\"Answer:\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7a432e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "To answer this question, we need to look for a column with 'Switzerland' or any reference to Switzerland.\n",
      "\n",
      "Looking at the data:\n",
      "\n",
      "- Natural | Glacial lake outburst flood | India | IND | 234 | 226806 | 2021 | 2238.127142 | N/A\n",
      "- Mass movement (wet) | Indonesia | Sierra Leone | SLE | 1102 | 35818 | 2017 | 484.4561288 | 1120.0\n",
      "\n",
      "There is no 'Switzerland' or any direct reference to Switzerland in the provided CSV data.\n",
      "\n",
      "Therefore, I cannot find this information in the CSV.\n"
     ]
    }
   ],
   "source": [
    "answer = ask(\"How much damage did Switzerland suffer?\")\n",
    "print(f\"Answer:\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd1b3a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "SELECT SUM(Total) FROM Natural\n"
     ]
    }
   ],
   "source": [
    "answer = ask(\"Summarize the total damage for all countries.\")\n",
    "print(f\"Answer:\\n{answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
